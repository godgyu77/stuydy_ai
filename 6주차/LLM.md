# 4장 텍스트 분류 (상세 정리)

## 4.1 텍스트 분류의 개요

* **정의**
  텍스트 분류는 주어진 텍스트를 특정한 레이블(label) 또는 클래스(class)에 자동으로 할당하는 작업입니다.
  예: 영화 리뷰 → `positive` / `negative`.

* **주요 응용 분야**

  * **감성 분석(Sentiment Analysis)**: 텍스트가 긍정적인지, 부정적인지 판별.
  * **의도 감지(Intent Detection)**: 챗봇이나 음성비서가 사용자의 의도를 파악.
  * **스팸 탐지(Spam Detection)**: 이메일/메시지에서 스팸 여부 분류.
  * **엔티티 추출(Entity Extraction)**: 문장에서 특정 개체(사람, 장소 등) 존재 여부 확인.
  * **언어 감지(Language Detection)**: 텍스트가 어느 언어인지 자동 분류.

* **언어 모델과의 관계**

  * **표현 언어 모델(Representation LM)**: 텍스트를 벡터로 임베딩 → 분류기(classifier)에 전달.
  * **생성 언어 모델(Generative LM)**: 프롬프트 기반으로 답변(분류 결과)을 직접 생성.
    → 두 접근법 모두 분류에 활용 가능하나 방식이 다릅니다 .

---

## 4.2 영화 리뷰 데이터셋

* **사용 데이터셋**: Rotten Tomatoes (허깅페이스 Hub에서 제공).
* **구성**:

  * 긍정 리뷰: 5,331개
  * 부정 리뷰: 5,331개
    → 완전한 균형 데이터셋 (binary classification).
* **출처**: Pang & Lee (2005), 감성 분석 연구에서 널리 사용된 벤치마크 .
* **실험 목적**: 사전 훈련된 모델과 다양한 접근법을 비교·평가.

---

## 4.3 표현 모델로 텍스트 분류하기

* **접근 방식**

  * 입력 텍스트 → 토크나이저로 분할 → 임베딩으로 변환 → 분류층(Dense Layer + Softmax 등) 통과 → 클래스 예측.

* **예시 모델**: BERT, DistilBERT, RoBERTa 등.

* **성능 평가 지표**:

  * **Precision / Recall / F1-score**
  * **Macro avg**: 클래스별 지표 평균 (클래스 불균형에 취약).
  * **Weighted avg**: 각 클래스 샘플 수로 가중 평균 → 더 실용적  .

* **실험 결과**

  * 사전 훈련된 BERT 모델: F1-score 약 0.8 → 영화 리뷰 데이터에 특화되지 않았음에도 높은 성능.
  * 도메인 특화 모델 사용 시 성능 향상 가능 (예: `distilbert-base-uncased-finetuned-sst-2-english`) .

---

## 4.4 작업 특화 모델 사용

* **특화 모델의 장점**

  * 특정 도메인 데이터(예: 감성 분석, 의료 텍스트 등)에서 학습된 모델은 일반 모델 대비 성능이 우수.
  * 추가 학습(fine-tuning) 필요성을 줄여줌.
* **예시**

  * SST-2 데이터로 학습된 DistilBERT → 감성 분석에 즉시 활용 가능.
* **전략**:

  * 범용 모델(BERT 등) → 작은 도메인 데이터로 fine-tuning.
  * Hugging Face Hub 등에서 도메인 특화 모델 검색 후 활용.

---

## 4.5 임베딩 기반 분류

* **동기**

  * 모든 상황에서 대형 모델을 직접 fine-tuning하기 어려움 (GPU, 비용 문제).
  * 따라서 **범용 임베딩 모델**을 활용해 텍스트를 벡터화 → 전통 ML 모델로 분류.

* **방식**

  * 입력 텍스트 → 임베딩 모델 (예: Sentence-BERT, Universal Sentence Encoder) → 벡터화.
  * 생성된 벡터 → 로지스틱 회귀 / SVM / 랜덤포레스트 등 ML 분류기에 입력.

* **4.5.1 지도 학습 분류**

  * 라벨이 있는 경우 → 학습/검증/테스트 데이터셋으로 나눔 → ML 분류 모델 학습.

* **4.5.2 비지도 학습 분류**

  * 라벨이 없는 경우 → 클러스터링(K-means, DBSCAN 등)으로 그룹화 → 후처리로 라벨링.

* **장점**

  * 적은 자원으로도 강력한 성능.
  * 새로운 도메인에 빠르게 적용 가능.

---

## 4.6 생성 모델로 텍스트 분류

* **접근 방식 차이**

  * 표현 모델: 입력 → 벡터화 → 분류기.
  * 생성 모델: 프롬프트에 직접 질문 → 출력 토큰이 곧 클래스 라벨.

* **4.6.1 T5 모델 활용**

  * 인코더-디코더 구조.
  * 입력: `"영화 리뷰: This movie was amazing. Sentiment:"`
  * 출력: `"positive"`
  * 분류를 일종의 **텍스트 생성 작업**으로 접근.

* **4.6.2 ChatGPT 활용**

  * **Zero-shot**: 예시 없이 프롬프트에 직접 질문.
  * **Few-shot**: 프롬프트에 예시 몇 개 포함 → 성능 크게 향상.
  * 장점: 별도 학습 없이 API 호출만으로 다양한 분류 수행.

---

## 4.7 요약

* **핵심 메시지**

  1. 텍스트 분류는 가장 기본적이고 널리 사용되는 NLP 작업.
  2. **표현 모델**: BERT 계열, 빠르고 효율적.
  3. **임베딩 기반 접근**: 범용 임베딩 + 전통 ML → 리소스 적게 소모.
  4. **생성 모델 접근**: 프롬프트 엔지니어링으로 분류 수행 가능 (T5, ChatGPT).
  5. 상황(데이터 크기, 자원, 목표)에 따라 최적 접근법 선택이 중요.

---